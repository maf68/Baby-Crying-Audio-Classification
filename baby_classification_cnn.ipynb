{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYb8YauIUqFh",
        "outputId": "08d7d4de-82ee-4bf6-d183-91f8daee9699",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (0.11.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.38.0)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.60.0)\n",
            "Requirement already satisfied: numpy>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from librosa) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.16.0)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.5.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.5.0.post1)\n",
            "Requirement already satisfied: typing_extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.14.1)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.1.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.11/dist-packages (from seaborn) (2.2.2)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.1.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.116.1)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.6.0)\n",
            "Requirement already satisfied: gradio-client==1.11.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.11.0)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.33.4)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.11.0)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.7)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.12.4)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.47.2)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.16.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.35.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.11.0->gradio) (2025.7.0)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.11.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1.0,>=0.24.1->gradio) (2025.7.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (1.1.5)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (4.3.8)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.5.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install librosa scikit-learn matplotlib seaborn gradio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Mount Google Drive to access dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BB5Bw0ESU75n",
        "outputId": "7fcf1952-6190-4406-d22c-e913010d70b1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "zip_path = '/content/drive/MyDrive/baby_cry_data.zip'\n",
        "extract_path = '/content/drive/MyDrive/baby_cry_data'\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)"
      ],
      "metadata": {
        "id": "mvp5MJTBWE1k"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking class distribution\n",
        "import os\n",
        "from collections import Counter\n",
        "\n",
        "base_dir = '/content/drive/MyDrive/baby_cry_data'\n",
        "classes = os.listdir(base_dir)\n",
        "\n",
        "class_counts = {}\n",
        "for cls in classes:\n",
        "    if not cls.startswith('.'):\n",
        "        files = os.listdir(os.path.join(base_dir, cls))\n",
        "        class_counts[cls] = len(files)\n",
        "\n",
        "print(class_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2RuWq-uBaIpz",
        "outputId": "2635b945-38b5-4e8f-c0c5-6eec1ce7b4b4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'BabyCryingSounds': 9, 'Baby Crying Sounds': 9}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert audio to mel spectogram\n",
        "import numpy as np\n",
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def audio_to_melspectrogram(file_path, max_len=128):\n",
        "    y, sr = librosa.load(file_path, sr=22050)\n",
        "    mels = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)\n",
        "    log_mels = librosa.power_to_db(mels, ref=np.max)\n",
        "\n",
        "    if log_mels.shape[1] < max_len:\n",
        "        pad_width = max_len - log_mels.shape[1]\n",
        "        log_mels = np.pad(log_mels, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
        "    else:\n",
        "        log_mels = log_mels[:, :max_len]\n",
        "\n",
        "    return log_mels"
      ],
      "metadata": {
        "id": "dTk557brbJry"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tqdm\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "label_map = {label: idx for idx, label in enumerate(sorted(class_counts.keys()))}\n",
        "\n",
        "audio_extensions = ('*.wav', '*.ogg')\n",
        "for label in label_map:\n",
        "    folder = os.path.join(base_dir, label)\n",
        "    for file in tqdm.tqdm(base_dir, desc=f\"Processing {label}\"):\n",
        "        file_path = os.path.join(folder, file)\n",
        "        if not file_path.lower().endswith(audio_extensions):\n",
        "            continue\n",
        "        try:\n",
        "            mel = audio_to_melspectrogram(file_path)\n",
        "            X.append(mel)\n",
        "            y.append(label_map[label])\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {file_path}: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ui14XuaLZmnb",
        "outputId": "27781f09-4937-46ba-daf8-aa6ee2aa0bc6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Baby Crying Sounds: 100%|██████████| 53/53 [00:00<00:00, 106159.56it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "from collections import defaultdict\n",
        "\n",
        "#Path to the main dataset folder on Google Drive\n",
        "base_dir = \"/content/drive/MyDrive/baby_cry_data/BabyCryingSounds\"\n",
        "\n",
        "#Classes in the dataset\n",
        "labels = ['belly pain', 'burping', 'cold_hot', 'discomfort',\n",
        "                   'hungry', 'laugh', 'noise', 'silence', 'tired']\n",
        "\n",
        "#Mapping: label name → list of audio file paths\n",
        "data_by_class = defaultdict(list)\n",
        "\n",
        "#Build class-to-files mapping\n",
        "audio_extensions = ('*.wav', '*.ogg')\n",
        "\n",
        "for label in labels:\n",
        "    folder_path = os.path.join(base_dir, label)\n",
        "    if os.path.exists(folder_path):\n",
        "        audio_files = []\n",
        "        for ext in audio_extensions:\n",
        "            audio_files.extend(glob.glob(os.path.join(folder_path, ext)))\n",
        "        data_by_class[label].extend(audio_files)\n",
        "        print(f\"✅ Loaded {len(audio_files)} files for class: {label}\")\n",
        "    else:\n",
        "        print(f\"⚠️ Folder not found for class: {label}\")\n",
        "\n",
        "print(\"\\n📊 Class distribution:\")\n",
        "for label, files in data_by_class.items():\n",
        "    print(f\"{label:12s} → {len(files)} files\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ofA4_LAQVyuw",
        "outputId": "29bd986b-7623-4672-dee3-098e4e8adec0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Loaded 124 files for class: belly pain\n",
            "✅ Loaded 108 files for class: burping\n",
            "✅ Loaded 108 files for class: cold_hot\n",
            "✅ Loaded 135 files for class: discomfort\n",
            "✅ Loaded 382 files for class: hungry\n",
            "✅ Loaded 108 files for class: laugh\n",
            "✅ Loaded 108 files for class: noise\n",
            "✅ Loaded 108 files for class: silence\n",
            "✅ Loaded 132 files for class: tired\n",
            "\n",
            "📊 Class distribution:\n",
            "belly pain   → 124 files\n",
            "burping      → 108 files\n",
            "cold_hot     → 108 files\n",
            "discomfort   → 135 files\n",
            "hungry       → 382 files\n",
            "laugh        → 108 files\n",
            "noise        → 108 files\n",
            "silence      → 108 files\n",
            "tired        → 132 files\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert Audio to Mel Spectrogram\n",
        "import librosa\n",
        "import numpy as np\n",
        "\n",
        "IMG_HEIGHT = 128\n",
        "IMG_WIDTH = 128\n",
        "\n",
        "def audio_to_mel(file_path):\n",
        "    y, sr = librosa.load(file_path, sr=22050)\n",
        "    mels = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=IMG_HEIGHT)\n",
        "    db = librosa.power_to_db(mels, ref=np.max)\n",
        "\n",
        "    if db.shape[1] < IMG_WIDTH:\n",
        "        pad = IMG_WIDTH - db.shape[1]\n",
        "        db = np.pad(db, ((0, 0), (0, pad)), mode='constant')\n",
        "    else:\n",
        "        db = db[:, :IMG_WIDTH]\n",
        "\n",
        "    return db"
      ],
      "metadata": {
        "id": "Dc2I6yvgZlYl"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Build Dataset\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "for label, file_paths in data_by_class.items():\n",
        "    for path in file_paths:\n",
        "        try:\n",
        "            mel = audio_to_mel(path)\n",
        "            X.append(mel)\n",
        "            y.append(label)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error: {path} - {e}\")\n",
        "\n",
        "X = np.array(X)\n",
        "X = X[..., np.newaxis]"
      ],
      "metadata": {
        "id": "RfYb6fgyh5HK"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "y = np.array(y)\n",
        "\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)\n",
        "\n",
        "y_cat = to_categorical(y_encoded)\n",
        "\n",
        "y_labels = le.inverse_transform(y_encoded)\n",
        "\n",
        "#First split: Train + Test (80/20)\n",
        "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
        "    X, y_labels, test_size=0.2, random_state=42, stratify=y_labels\n",
        ")\n",
        "\n",
        "#Second split: Train + Val (80/20 of the remaining → 64/16 overall)\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_train_val, y_train_val, test_size=0.2, random_state=42, stratify=y_train_val\n",
        ")"
      ],
      "metadata": {
        "id": "wYBKuBvlh413"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "output_base = '/content/baby_cry_split'\n",
        "\n",
        "#Create directories for train, val, test\n",
        "for split in ['train', 'val', 'test']:\n",
        "    for class_name in le.classes_:\n",
        "        os.makedirs(os.path.join(output_base, split, class_name), exist_ok=True)\n",
        "\n",
        "def save_split(X_split, y_split, split_name):\n",
        "    for idx, (mel, label) in enumerate(tqdm(zip(X_split, y_split), total=len(X_split), desc=f\"Saving {split_name}\")):\n",
        "        save_path = os.path.join(output_base, split_name, label, f\"mel_{idx}.npy\")\n",
        "        np.save(save_path, mel)\n",
        "\n",
        "save_split(X_train, y_train, 'train')\n",
        "save_split(X_val, y_val, 'val')\n",
        "save_split(X_test, y_test, 'test')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qHU4Aj72Qpd",
        "outputId": "8adb0bef-42d5-42f6-dcf3-7f64480a187d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving train: 100%|██████████| 840/840 [00:00<00:00, 1854.69it/s]\n",
            "Saving val: 100%|██████████| 210/210 [00:00<00:00, 1976.93it/s]\n",
            "Saving test: 100%|██████████| 263/263 [00:00<00:00, 1976.72it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model training cnn resnet **18**"
      ],
      "metadata": {
        "id": "_N024hEOVYvH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1CwLr3tbA7I",
        "outputId": "06c2815a-817e-4675-c171-daf81a53ca27"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y sympy\n",
        "!pip install sympy==1.12"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "0zRmndVYQJdc",
        "outputId": "07e92379-1859-4933-c691-6fe49428ca05"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: sympy 1.13.1\n",
            "Uninstalling sympy-1.13.1:\n",
            "  Successfully uninstalled sympy-1.13.1\n",
            "Collecting sympy==1.12\n",
            "  Downloading sympy-1.12-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.11/dist-packages (from sympy==1.12) (1.3.0)\n",
            "Downloading sympy-1.12-py3-none-any.whl (5.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m39.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sympy\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.6.0+cu124 requires sympy==1.13.1; python_version >= \"3.9\", but you have sympy 1.12 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed sympy-1.12\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "sympy"
                ]
              },
              "id": "124c9b2c06de4dc3b170fedf863e3c43"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNN Base Model"
      ],
      "metadata": {
        "id": "25z706k0GWVw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "# Hyperparameters\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 50\n",
        "LEARNING_RATE = 1e-3\n",
        "PATIENCE = 5  #For early stopping\n",
        "\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(128),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "val_transforms = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "data_dir = '/content/baby_cry_split/'\n",
        "try:\n",
        "    train_dataset = CryDataset(f\"{data_dir}/train\", transform=train_transforms)\n",
        "    val_dataset = CryDataset(f\"{data_dir}/val\", transform=val_transforms)\n",
        "\n",
        "    #We check if datasets are empty before creating DataLoaders\n",
        "    if len(train_dataset) == 0:\n",
        "        print(\"Error: Training dataset is empty. Cannot create DataLoader.\")\n",
        "        train_loader = None\n",
        "    else:\n",
        "        train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, collate_fn=custom_collate_fn) # Use custom collate_fn\n",
        "        print(f\"Training dataset size: {len(train_dataset)}\")\n",
        "\n",
        "\n",
        "    if len(val_dataset) == 0:\n",
        "        print(\"Error: Validation dataset is empty. Cannot create DataLoader.\")\n",
        "        val_loader = None\n",
        "    else:\n",
        "        val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, collate_fn=custom_collate_fn) # Use custom collate_fn\n",
        "        print(f\"Validation dataset size: {len(val_dataset)}\")\n",
        "\n",
        "    #Determine the number of classes from the training dataset\n",
        "    if train_dataset is not None:\n",
        "         NUM_CLASSES = len(train_dataset.classes)\n",
        "         print(f\"Number of classes: {NUM_CLASSES}\")\n",
        "    else:\n",
        "         print(\"Error: Could not determine the number of classes from the training dataset.\")\n",
        "         NUM_CLASSES = 0\n",
        "\n",
        "except NameError:\n",
        "    print(\"Error: CryDataset or custom_collate_fn not defined. Please ensure the cell defining them is executed.\")\n",
        "    train_loader = None\n",
        "    val_loader = None\n",
        "    NUM_CLASSES = 0\n",
        "\n",
        "model = None\n",
        "if NUM_CLASSES > 0:\n",
        "    class BaseCNN(nn.Module):\n",
        "        def __init__(self, num_classes):\n",
        "            super(BaseCNN, self).__init__()\n",
        "            self.features = nn.Sequential(\n",
        "                nn.Conv2d(3, 32, 3, padding=1),\n",
        "                nn.BatchNorm2d(32),\n",
        "                nn.ReLU(),\n",
        "                nn.MaxPool2d(2),\n",
        "\n",
        "                nn.Conv2d(32, 64, 3, padding=1),\n",
        "                nn.BatchNorm2d(64),\n",
        "                nn.ReLU(),\n",
        "                nn.MaxPool2d(2),\n",
        "\n",
        "                nn.Conv2d(64, 128, 3, padding=1),\n",
        "                nn.BatchNorm2d(128),\n",
        "                nn.ReLU(),\n",
        "                nn.MaxPool2d(2),\n",
        "\n",
        "                nn.Dropout(0.3)  #For regularization\n",
        "            )\n",
        "            self.classifier = nn.Sequential(\n",
        "                nn.Flatten(),\n",
        "                nn.Linear(128 * 16 * 16, 256),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout(0.5),  #For regularization\n",
        "                nn.Linear(256, num_classes)\n",
        "            )\n",
        "\n",
        "        def forward(self, x):\n",
        "            x = self.features(x)\n",
        "            x = self.classifier(x)\n",
        "            return x\n",
        "\n",
        "    model = BaseCNN(num_classes=NUM_CLASSES).to(device)\n",
        "    print(\"Base CNN model loaded.\")\n",
        "else:\n",
        "    print(\"Base CNN model not loaded due to insufficient number of classes.\")\n",
        "\n",
        "criterion = None\n",
        "optimizer = None\n",
        "\n",
        "if model is not None:\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-4)\n",
        "    print(\"Loss and optimizer initialized.\")\n",
        "else:\n",
        "    print(\"Loss and optimizer not initialized as model was not loaded.\")\n",
        "\n",
        "best_val_loss = float('inf')\n",
        "patience_counter = 0\n",
        "\n",
        "if train_loader is not None and val_loader is not None and model is not None:\n",
        "    for epoch in range(EPOCHS):\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1} [Train]\"):\n",
        "            if images.size(0) == 0:\n",
        "                 continue\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item() * images.size(0)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "        avg_train_loss = train_loss / total if total > 0 else 0\n",
        "        train_acc = correct / total if total > 0 else 0\n",
        "\n",
        "\n",
        "        #Validation phase\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        val_correct = 0\n",
        "        val_total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for images, labels in tqdm(val_loader, desc=f\"Epoch {epoch+1} [Val]\"):\n",
        "                if images.size(0) == 0:\n",
        "                     continue\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                val_loss += loss.item() * images.size(0)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                val_correct += (preds == labels).sum().item()\n",
        "                val_total += labels.size(0)\n",
        "\n",
        "        avg_val_loss = val_loss / val_total if val_total > 0 else 0\n",
        "        val_acc = val_correct / val_total if val_total > 0 else 0\n",
        "\n",
        "\n",
        "        print(f\"\\n📊 Epoch {epoch+1} | Train Loss: {avg_train_loss:.4f} | Train Acc: {train_acc:.3f} | \"\n",
        "              f\"Val Loss: {avg_val_loss:.4f} | Val Acc: {val_acc:.3f}\")\n",
        "\n",
        "        if avg_val_loss < best_val_loss:\n",
        "            best_val_loss = avg_val_loss\n",
        "            torch.save(model.state_dict(), 'best_cnn_model.pth')\n",
        "            patience_counter = 0\n",
        "            print(\"✅ Best model saved.\")\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            if patience_counter >= PATIENCE:\n",
        "                print(\"⏹️ Early stopping triggered.\")\n",
        "                break\n",
        "\n",
        "    try:\n",
        "        model.load_state_dict(torch.load('best_cnn_model.pth'))\n",
        "        print(\"✅ Best model loaded.\")\n",
        "    except FileNotFoundError:\n",
        "        print(\"⚠️ Best model file not found. Skipping model loading.\")\n",
        "\n",
        "else:\n",
        "    print(\"\\nTraining skipped due to empty dataset(s) or model loading failure.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qithTJaSGTlF",
        "outputId": "3efc66b9-2866-4d08-807b-6f805cc985d3"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚀 Using device: cpu\n",
            "Training dataset size: 840\n",
            "Validation dataset size: 210\n",
            "Number of classes: 9\n",
            "Base CNN model loaded.\n",
            "Loss and optimizer initialized.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1 [Train]: 100%|██████████| 14/14 [00:47<00:00,  3.41s/it]\n",
            "Epoch 1 [Val]: 100%|██████████| 4/4 [00:05<00:00,  1.32s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 1 | Train Loss: 7.6468 | Train Acc: 0.168 | Val Loss: 2.1678 | Val Acc: 0.305\n",
            "✅ Best model saved.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2 [Train]: 100%|██████████| 14/14 [00:46<00:00,  3.33s/it]\n",
            "Epoch 2 [Val]: 100%|██████████| 4/4 [00:04<00:00,  1.20s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 2 | Train Loss: 2.1890 | Train Acc: 0.173 | Val Loss: 2.0315 | Val Acc: 0.371\n",
            "✅ Best model saved.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3 [Train]: 100%|██████████| 14/14 [00:44<00:00,  3.17s/it]\n",
            "Epoch 3 [Val]: 100%|██████████| 4/4 [00:06<00:00,  1.52s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 3 | Train Loss: 2.0832 | Train Acc: 0.181 | Val Loss: 1.8510 | Val Acc: 0.371\n",
            "✅ Best model saved.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4 [Train]: 100%|██████████| 14/14 [00:45<00:00,  3.25s/it]\n",
            "Epoch 4 [Val]: 100%|██████████| 4/4 [00:04<00:00,  1.18s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 4 | Train Loss: 2.0515 | Train Acc: 0.218 | Val Loss: 1.8149 | Val Acc: 0.371\n",
            "✅ Best model saved.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5 [Train]: 100%|██████████| 14/14 [00:46<00:00,  3.30s/it]\n",
            "Epoch 5 [Val]: 100%|██████████| 4/4 [00:05<00:00,  1.38s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 5 | Train Loss: 2.0104 | Train Acc: 0.262 | Val Loss: 1.7788 | Val Acc: 0.371\n",
            "✅ Best model saved.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6 [Train]: 100%|██████████| 14/14 [00:44<00:00,  3.16s/it]\n",
            "Epoch 6 [Val]: 100%|██████████| 4/4 [00:05<00:00,  1.29s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 6 | Train Loss: 2.0221 | Train Acc: 0.267 | Val Loss: 1.7430 | Val Acc: 0.371\n",
            "✅ Best model saved.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7 [Train]: 100%|██████████| 14/14 [00:45<00:00,  3.25s/it]\n",
            "Epoch 7 [Val]: 100%|██████████| 4/4 [00:04<00:00,  1.21s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 7 | Train Loss: 1.9939 | Train Acc: 0.313 | Val Loss: 1.7691 | Val Acc: 0.371\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8 [Train]: 100%|██████████| 14/14 [00:44<00:00,  3.19s/it]\n",
            "Epoch 8 [Val]: 100%|██████████| 4/4 [00:05<00:00,  1.46s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 8 | Train Loss: 1.9727 | Train Acc: 0.330 | Val Loss: 1.7554 | Val Acc: 0.371\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9 [Train]: 100%|██████████| 14/14 [00:45<00:00,  3.22s/it]\n",
            "Epoch 9 [Val]: 100%|██████████| 4/4 [00:04<00:00,  1.19s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 9 | Train Loss: 2.0002 | Train Acc: 0.336 | Val Loss: 1.7227 | Val Acc: 0.371\n",
            "✅ Best model saved.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10 [Train]: 100%|██████████| 14/14 [00:45<00:00,  3.25s/it]\n",
            "Epoch 10 [Val]: 100%|██████████| 4/4 [00:05<00:00,  1.46s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 10 | Train Loss: 1.9475 | Train Acc: 0.330 | Val Loss: 1.7627 | Val Acc: 0.367\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11 [Train]: 100%|██████████| 14/14 [00:45<00:00,  3.25s/it]\n",
            "Epoch 11 [Val]: 100%|██████████| 4/4 [00:05<00:00,  1.32s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 11 | Train Loss: 1.9344 | Train Acc: 0.339 | Val Loss: 1.7519 | Val Acc: 0.371\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12 [Train]: 100%|██████████| 14/14 [00:45<00:00,  3.25s/it]\n",
            "Epoch 12 [Val]: 100%|██████████| 4/4 [00:04<00:00,  1.22s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 12 | Train Loss: 1.9605 | Train Acc: 0.336 | Val Loss: 1.7455 | Val Acc: 0.371\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13 [Train]: 100%|██████████| 14/14 [00:44<00:00,  3.18s/it]\n",
            "Epoch 13 [Val]: 100%|██████████| 4/4 [00:06<00:00,  1.51s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 13 | Train Loss: 1.9230 | Train Acc: 0.342 | Val Loss: 1.7243 | Val Acc: 0.371\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14 [Train]: 100%|██████████| 14/14 [00:44<00:00,  3.19s/it]\n",
            "Epoch 14 [Val]: 100%|██████████| 4/4 [00:04<00:00,  1.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 14 | Train Loss: 1.9173 | Train Acc: 0.348 | Val Loss: 1.7897 | Val Acc: 0.371\n",
            "⏹️ Early stopping triggered.\n",
            "✅ Best model loaded.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "EfficientNet_B0"
      ],
      "metadata": {
        "id": "v7CID5vw5dhc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms\n",
        "from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 30\n",
        "LR = 1e-3\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.5]*3, std=[0.5]*3)\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.5]*3, std=[0.5]*3)\n",
        "    ])\n",
        "}\n",
        "\n",
        "data_dir = '/content/baby_cry_split/'\n",
        "datasets = {\n",
        "    x: CryDataset(f\"{data_dir}/{x}\", data_transforms[x])\n",
        "    for x in ['train', 'val']\n",
        "}\n",
        "\n",
        "dataloaders = {}\n",
        "if len(datasets['train']) == 0:\n",
        "    print(\"Error: Training dataset is empty. Cannot create DataLoader.\")\n",
        "    train_loader = None\n",
        "else:\n",
        "    dataloaders['train'] = DataLoader(datasets['train'], batch_size=BATCH_SIZE, shuffle=True, collate_fn=custom_collate_fn)\n",
        "    print(f\"Training dataset size: {len(datasets['train'])}\")\n",
        "\n",
        "\n",
        "if len(datasets['val']) == 0:\n",
        "    print(\"Error: Validation dataset is empty. Cannot create DataLoader.\")\n",
        "    val_loader = None\n",
        "else:\n",
        "    dataloaders['val'] = DataLoader(datasets['val'], batch_size=BATCH_SIZE, shuffle=False, collate_fn=custom_collate_fn)\n",
        "    print(f\"Validation dataset size: {len(datasets['val'])}\")\n",
        "\n",
        "\n",
        "if 'train' in dataloaders and datasets['train'] is not None:\n",
        "    NUM_CLASSES = len(datasets['train'].classes)\n",
        "    print(f\"Number of classes: {NUM_CLASSES}\")\n",
        "else:\n",
        "    print(\"Error: Could not determine the number of classes from the training dataset.\")\n",
        "    NUM_CLASSES = 0\n",
        "\n",
        "\n",
        "model = None\n",
        "if NUM_CLASSES > 0:\n",
        "    model = efficientnet_b0(weights=EfficientNet_B0_Weights.DEFAULT)\n",
        "    model.classifier[1] = nn.Linear(model.classifier[1].in_features, NUM_CLASSES)\n",
        "    model = model.to(DEVICE)\n",
        "\n",
        "    #Unfreeze deeper layers for fine-tuning\n",
        "    for name, param in model.features.named_parameters():\n",
        "        #Unfreeze blocks 4, 5, 6, 7 and the classifier\n",
        "        if any(block in name for block in [\"4\", \"5\", \"6\", \"7\"]) or 'classifier' in name:\n",
        "             param.requires_grad = True\n",
        "        else:\n",
        "             param.requires_grad = False\n",
        "    print(\"Model loaded and modified for fine-tuning.\")\n",
        "else:\n",
        "    print(\"Model not loaded due to insufficient number of classes.\")\n",
        "\n",
        "\n",
        "criterion = None\n",
        "optimizer = None\n",
        "scheduler = None\n",
        "\n",
        "if model is not None:\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=LR)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)\n",
        "    print(\"Loss, Optimizer, and Scheduler initialized.\")\n",
        "else:\n",
        "    print(\"Loss, Optimizer, and Scheduler not initialized as model was not loaded.\")\n",
        "\n",
        "def mixup_data(x, y, alpha=1.0):\n",
        "    if x.size(0) == 0:\n",
        "        return x, y, y, 0.0\n",
        "    lam = np.random.beta(alpha, alpha)\n",
        "    index = torch.randperm(x.size(0)).to(x.device)\n",
        "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
        "    y_a, y_b = y, y[index]\n",
        "    return mixed_x, y_a, y_b, lam\n",
        "\n",
        "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
        "    if pred.size(0) == 0:\n",
        "        return torch.tensor(0.0, device=pred.device, requires_grad=True)\n",
        "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n",
        "\n",
        "\n",
        "best_val_acc = 0.0\n",
        "if 'train' in dataloaders and 'val' in dataloaders and model is not None:\n",
        "    for epoch in range(EPOCHS):\n",
        "        print(f\"\\nEpoch {epoch+1:02d}\")\n",
        "\n",
        "        model.train()\n",
        "        running_loss, running_corrects = 0.0, 0\n",
        "        total_train_samples = 0\n",
        "\n",
        "        for inputs, labels in dataloaders['train']:\n",
        "            if inputs.size(0) == 0:\n",
        "                continue\n",
        "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
        "\n",
        "            inputs, targets_a, targets_b, lam = mixup_data(inputs, labels)\n",
        "            outputs = model(inputs)\n",
        "            loss = mixup_criterion(criterion, outputs, targets_a, targets_b, lam)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            running_corrects += (lam * preds.eq(targets_a).sum().item() + (1 - lam) * preds.eq(targets_b).sum().item())\n",
        "            total_train_samples += inputs.size(0)\n",
        "\n",
        "\n",
        "        epoch_loss = running_loss / total_train_samples if total_train_samples > 0 else 0.0\n",
        "        epoch_acc = running_corrects / total_train_samples if total_train_samples > 0 else 0.0\n",
        "        print(f\"Train Loss: {epoch_loss:.4f} | Train Acc: {epoch_acc:.3f}\")\n",
        "\n",
        "        model.eval()\n",
        "        val_loss, val_corrects = 0.0, 0\n",
        "        total_val_samples = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in dataloaders['val']:\n",
        "                if inputs.size(0) == 0:\n",
        "                    continue\n",
        "                inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                val_loss += loss.item() * inputs.size(0)\n",
        "                val_corrects += torch.sum(preds == labels).item()\n",
        "                total_val_samples += inputs.size(0)\n",
        "\n",
        "\n",
        "        val_epoch_loss = val_loss / total_val_samples if total_val_samples > 0 else 0.0\n",
        "        val_epoch_acc = val_corrects / total_val_samples if total_val_samples > 0 else 0.0\n",
        "        print(f\"Val Loss: {val_epoch_loss:.4f} | Val Acc: {val_epoch_acc:.3f}\")\n",
        "\n",
        "        if total_val_samples > 0:\n",
        "             scheduler.step(val_epoch_loss)\n",
        "\n",
        "        if val_epoch_acc > best_val_acc:\n",
        "            best_val_acc = val_epoch_acc\n",
        "            torch.save(model.state_dict(), \"best_model.pth\")\n",
        "            print(\"✅ Best model saved!\")\n",
        "    print(\"\\nTraining complete.\")\n",
        "\n",
        "else:\n",
        "    print(\"\\nTraining skipped due to empty dataset(s) or model loading failure.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wf0LKz-D5J_K",
        "outputId": "3fe0b4d4-c6fb-4bbe-8d22-bd8ea9df5a06"
      },
      "execution_count": 30,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training dataset size: 840\n",
            "Validation dataset size: 210\n",
            "Number of classes: 9\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b0_rwightman-7f5810bc.pth\n",
            "100%|██████████| 20.5M/20.5M [00:00<00:00, 86.8MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded and modified for fine-tuning.\n",
            "Loss, Optimizer, and Scheduler initialized.\n",
            "\n",
            "Epoch 01\n",
            "Train Loss: 1.8262 | Train Acc: 0.381\n",
            "Val Loss: 1.7669 | Val Acc: 0.395\n",
            "✅ Best model saved!\n",
            "\n",
            "Epoch 02\n",
            "Train Loss: 1.6117 | Train Acc: 0.459\n",
            "Val Loss: 1.7212 | Val Acc: 0.262\n",
            "\n",
            "Epoch 03\n",
            "Train Loss: 1.5225 | Train Acc: 0.487\n",
            "Val Loss: 1.4301 | Val Acc: 0.510\n",
            "✅ Best model saved!\n",
            "\n",
            "Epoch 04\n",
            "Train Loss: 1.4636 | Train Acc: 0.479\n",
            "Val Loss: 1.3209 | Val Acc: 0.524\n",
            "✅ Best model saved!\n",
            "\n",
            "Epoch 05\n",
            "Train Loss: 1.4399 | Train Acc: 0.508\n",
            "Val Loss: 1.3187 | Val Acc: 0.505\n",
            "\n",
            "Epoch 06\n",
            "Train Loss: 1.4230 | Train Acc: 0.500\n",
            "Val Loss: 1.3645 | Val Acc: 0.433\n",
            "\n",
            "Epoch 07\n",
            "Train Loss: 1.3712 | Train Acc: 0.523\n",
            "Val Loss: 1.4016 | Val Acc: 0.481\n",
            "\n",
            "Epoch 08\n",
            "Train Loss: 1.3164 | Train Acc: 0.540\n",
            "Val Loss: 1.4765 | Val Acc: 0.452\n",
            "\n",
            "Epoch 09\n",
            "Train Loss: 1.3281 | Train Acc: 0.525\n",
            "Val Loss: 1.5206 | Val Acc: 0.471\n",
            "\n",
            "Epoch 10\n",
            "Train Loss: 1.2167 | Train Acc: 0.572\n",
            "Val Loss: 1.6098 | Val Acc: 0.419\n",
            "\n",
            "Epoch 11\n",
            "Train Loss: 1.1563 | Train Acc: 0.589\n",
            "Val Loss: 1.6235 | Val Acc: 0.462\n",
            "\n",
            "Epoch 12\n",
            "Train Loss: 1.2954 | Train Acc: 0.518\n",
            "Val Loss: 1.5798 | Val Acc: 0.429\n",
            "\n",
            "Epoch 13\n",
            "Train Loss: 1.1383 | Train Acc: 0.572\n",
            "Val Loss: 1.6984 | Val Acc: 0.433\n",
            "\n",
            "Epoch 14\n",
            "Train Loss: 1.1302 | Train Acc: 0.594\n",
            "Val Loss: 1.7097 | Val Acc: 0.424\n",
            "\n",
            "Epoch 15\n",
            "Train Loss: 1.1718 | Train Acc: 0.583\n",
            "Val Loss: 1.7103 | Val Acc: 0.414\n",
            "\n",
            "Epoch 16\n",
            "Train Loss: 1.0597 | Train Acc: 0.603\n",
            "Val Loss: 1.7394 | Val Acc: 0.405\n",
            "\n",
            "Epoch 17\n",
            "Train Loss: 1.1611 | Train Acc: 0.571\n",
            "Val Loss: 1.8505 | Val Acc: 0.410\n",
            "\n",
            "Epoch 18\n",
            "Train Loss: 1.0214 | Train Acc: 0.629\n",
            "Val Loss: 1.8661 | Val Acc: 0.405\n",
            "\n",
            "Epoch 19\n",
            "Train Loss: 1.0320 | Train Acc: 0.617\n",
            "Val Loss: 1.8595 | Val Acc: 0.405\n",
            "\n",
            "Epoch 20\n",
            "Train Loss: 1.1035 | Train Acc: 0.586\n",
            "Val Loss: 1.8798 | Val Acc: 0.405\n",
            "\n",
            "Epoch 21\n",
            "Train Loss: 0.9900 | Train Acc: 0.627\n",
            "Val Loss: 1.8812 | Val Acc: 0.400\n",
            "\n",
            "Epoch 22\n",
            "Train Loss: 1.0587 | Train Acc: 0.592\n",
            "Val Loss: 1.8868 | Val Acc: 0.400\n",
            "\n",
            "Epoch 23\n",
            "Train Loss: 1.0008 | Train Acc: 0.647\n",
            "Val Loss: 1.8999 | Val Acc: 0.400\n",
            "\n",
            "Epoch 24\n",
            "Train Loss: 1.0596 | Train Acc: 0.620\n",
            "Val Loss: 1.8860 | Val Acc: 0.405\n",
            "\n",
            "Epoch 25\n",
            "Train Loss: 1.0548 | Train Acc: 0.592\n",
            "Val Loss: 1.8899 | Val Acc: 0.400\n",
            "\n",
            "Epoch 26\n",
            "Train Loss: 1.1212 | Train Acc: 0.585\n",
            "Val Loss: 1.9009 | Val Acc: 0.405\n",
            "\n",
            "Epoch 27\n",
            "Train Loss: 0.9795 | Train Acc: 0.627\n",
            "Val Loss: 1.8889 | Val Acc: 0.405\n",
            "\n",
            "Epoch 28\n",
            "Train Loss: 1.0350 | Train Acc: 0.611\n",
            "Val Loss: 1.9023 | Val Acc: 0.405\n",
            "\n",
            "Epoch 29\n",
            "Train Loss: 1.0333 | Train Acc: 0.608\n",
            "Val Loss: 1.9079 | Val Acc: 0.400\n",
            "\n",
            "Epoch 30\n",
            "Train Loss: 1.0275 | Train Acc: 0.612\n",
            "Val Loss: 1.9305 | Val Acc: 0.405\n",
            "\n",
            "Training complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# mobile v3net"
      ],
      "metadata": {
        "id": "jU2dkwBUdc8P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import models, transforms\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from tqdm import tqdm\n",
        "\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "class CryDataset(Dataset):\n",
        "    def __init__(self, folder, transform=None):\n",
        "        self.paths, self.labels = [], []\n",
        "        for label in sorted(os.listdir(folder)):\n",
        "            class_dir = os.path.join(folder, label)\n",
        "            if os.path.isdir(class_dir):\n",
        "                for file in os.listdir(class_dir):\n",
        "                    if file.endswith(\".npy\"):\n",
        "                        self.paths.append(os.path.join(class_dir, file))\n",
        "                        self.labels.append(label)\n",
        "        self.classes = sorted(list(set(self.labels)))\n",
        "        self.class_to_idx = {cls: i for i, cls in enumerate(self.classes)}\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self): return len(self.paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        path = self.paths[idx]\n",
        "        label_str = self.labels[idx]\n",
        "        label = self.class_to_idx[label_str]\n",
        "        try:\n",
        "            mel_spec = np.load(path)\n",
        "            mel_spec = np.squeeze(mel_spec)\n",
        "            mel_norm = (mel_spec - mel_spec.min()) / (mel_spec.max() - mel_spec.min() + 1e-6)\n",
        "            img = Image.fromarray((mel_norm * 255).astype(np.uint8)).resize((224, 224)).convert(\"RGB\")\n",
        "            if self.transform: img = self.transform(img)\n",
        "            return img, label\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading {path}: {e}\")\n",
        "            return None, None\n",
        "\n",
        "def custom_collate_fn(batch):\n",
        "    batch = [b for b in batch if b[0] is not None]\n",
        "    if len(batch) == 0: return torch.empty(0), torch.empty(0)\n",
        "    imgs, labels = zip(*batch)\n",
        "    return torch.stack(imgs), torch.tensor(labels)\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224, scale=(0.6, 1.0)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.3, hue=0.02),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5]*3, std=[0.5]*3)\n",
        "])\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5]*3, std=[0.5]*3)\n",
        "])\n",
        "\n",
        "train_data = CryDataset(\"/content/baby_cry_split/train\", transform=train_transform)\n",
        "val_data = CryDataset(\"/content/baby_cry_split/val\", transform=val_transform)\n",
        "\n",
        "batch_size = 16\n",
        "num_workers = 2\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True,\n",
        "                          collate_fn=custom_collate_fn, num_workers=num_workers)\n",
        "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False,\n",
        "                        collate_fn=custom_collate_fn, num_workers=num_workers)\n",
        "\n",
        "train_labels = [train_data.class_to_idx[label] for label in train_data.labels]\n",
        "class_weights = torch.tensor(\n",
        "    compute_class_weight('balanced', classes=np.unique(train_labels), y=train_labels),\n",
        "    dtype=torch.float\n",
        ")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"🚀 Using device:\", device)\n",
        "\n",
        "model = models.mobilenet_v3_large(weights=models.MobileNet_V3_Large_Weights.DEFAULT)\n",
        "\n",
        "for param in model.features.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "model.classifier = nn.Sequential(\n",
        "    nn.Linear(model.classifier[0].in_features, 256),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.6),\n",
        "    nn.Linear(256, len(train_data.classes))\n",
        ")\n",
        "model = model.to(device)\n",
        "\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights.to(device), label_smoothing=0.1)\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.5, verbose=True)\n",
        "\n",
        "\n",
        "best_val_loss = float(\"inf\")\n",
        "no_improve = 0\n",
        "early_stop_patience = 6\n",
        "max_epochs = 30\n",
        "\n",
        "for epoch in range(1, max_epochs + 1):\n",
        "    model.train()\n",
        "    train_loss, correct, total = 0.0, 0, 0\n",
        "\n",
        "    loop = tqdm(train_loader, desc=f\"Epoch {epoch:02d} [Train]\")\n",
        "    for X, y in loop:\n",
        "        if X.size(0) == 0: continue\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(X)\n",
        "        loss = criterion(outputs, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item() * X.size(0)\n",
        "        correct += (outputs.argmax(1) == y).sum().item()\n",
        "        total += X.size(0)\n",
        "        loop.set_postfix(loss=loss.item())\n",
        "\n",
        "    train_loss /= total\n",
        "    train_acc = correct / total\n",
        "\n",
        "    model.eval()\n",
        "    val_loss, val_correct, val_total = 0.0, 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in tqdm(val_loader, desc=f\"Epoch {epoch:02d} [Val]\"):\n",
        "            if X.size(0) == 0: continue\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            outputs = model(X)\n",
        "            loss = criterion(outputs, y)\n",
        "            val_loss += loss.item() * X.size(0)\n",
        "            val_correct += (outputs.argmax(1) == y).sum().item()\n",
        "            val_total += X.size(0)\n",
        "\n",
        "    val_loss /= val_total\n",
        "    val_acc = val_correct / val_total\n",
        "\n",
        "    print(f\"\\n📊 Epoch {epoch:02d} | Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.3f} | Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.3f}\")\n",
        "    scheduler.step(val_loss)\n",
        "\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        torch.save(model.state_dict(), \"best_model.pth\")\n",
        "        no_improve = 0\n",
        "    else:\n",
        "        no_improve += 1\n",
        "        if no_improve >= early_stop_patience:\n",
        "            print(\"⏹️ Early stopping triggered.\")\n",
        "            break\n",
        "\n",
        "try:\n",
        "    model.load_state_dict(torch.load(\"best_model.pth\"))\n",
        "    model.eval()\n",
        "    print(\"✅ Best model loaded.\")\n",
        "except FileNotFoundError:\n",
        "    print(\"⚠️ No saved model found.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ogE3Sx9daek",
        "outputId": "39cf6ac0-a1d7-49d2-c7ea-71875eb113fd"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚀 Using device: cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/mobilenet_v3_large-5c1a4163.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v3_large-5c1a4163.pth\n",
            "100%|██████████| 21.1M/21.1M [00:00<00:00, 60.0MB/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n",
            "Epoch 01 [Train]: 100%|██████████| 53/53 [00:41<00:00,  1.29it/s, loss=2.2]\n",
            "Epoch 01 [Val]: 100%|██████████| 14/14 [00:05<00:00,  2.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 01 | Train Loss: 2.2105 | Train Acc: 0.167 | Val Loss: 2.2786 | Val Acc: 0.276\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 02 [Train]: 100%|██████████| 53/53 [00:35<00:00,  1.49it/s, loss=2.03]\n",
            "Epoch 02 [Val]: 100%|██████████| 14/14 [00:05<00:00,  2.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 02 | Train Loss: 2.1419 | Train Acc: 0.218 | Val Loss: 2.2442 | Val Acc: 0.276\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 03 [Train]: 100%|██████████| 53/53 [00:34<00:00,  1.54it/s, loss=2.21]\n",
            "Epoch 03 [Val]: 100%|██████████| 14/14 [00:06<00:00,  2.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 03 | Train Loss: 2.0811 | Train Acc: 0.285 | Val Loss: 2.2022 | Val Acc: 0.343\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 04 [Train]: 100%|██████████| 53/53 [00:34<00:00,  1.54it/s, loss=1.89]\n",
            "Epoch 04 [Val]: 100%|██████████| 14/14 [00:06<00:00,  2.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 04 | Train Loss: 2.0087 | Train Acc: 0.299 | Val Loss: 2.1599 | Val Acc: 0.386\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 05 [Train]: 100%|██████████| 53/53 [00:34<00:00,  1.54it/s, loss=1.87]\n",
            "Epoch 05 [Val]: 100%|██████████| 14/14 [00:06<00:00,  2.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 05 | Train Loss: 1.9534 | Train Acc: 0.305 | Val Loss: 2.1218 | Val Acc: 0.371\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 06 [Train]: 100%|██████████| 53/53 [00:34<00:00,  1.54it/s, loss=1.96]\n",
            "Epoch 06 [Val]: 100%|██████████| 14/14 [00:06<00:00,  2.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 06 | Train Loss: 1.9112 | Train Acc: 0.311 | Val Loss: 2.0795 | Val Acc: 0.362\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 07 [Train]: 100%|██████████| 53/53 [00:35<00:00,  1.51it/s, loss=1.82]\n",
            "Epoch 07 [Val]: 100%|██████████| 14/14 [00:06<00:00,  2.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 07 | Train Loss: 1.8798 | Train Acc: 0.318 | Val Loss: 2.0498 | Val Acc: 0.324\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 08 [Train]: 100%|██████████| 53/53 [00:35<00:00,  1.51it/s, loss=1.94]\n",
            "Epoch 08 [Val]: 100%|██████████| 14/14 [00:05<00:00,  2.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 08 | Train Loss: 1.8386 | Train Acc: 0.340 | Val Loss: 2.0271 | Val Acc: 0.329\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 09 [Train]: 100%|██████████| 53/53 [00:35<00:00,  1.49it/s, loss=2.2]\n",
            "Epoch 09 [Val]: 100%|██████████| 14/14 [00:05<00:00,  2.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 09 | Train Loss: 1.8316 | Train Acc: 0.335 | Val Loss: 2.0153 | Val Acc: 0.286\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10 [Train]: 100%|██████████| 53/53 [00:35<00:00,  1.49it/s, loss=1.64]\n",
            "Epoch 10 [Val]: 100%|██████████| 14/14 [00:05<00:00,  2.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 10 | Train Loss: 1.7928 | Train Acc: 0.350 | Val Loss: 2.0037 | Val Acc: 0.262\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11 [Train]: 100%|██████████| 53/53 [00:35<00:00,  1.49it/s, loss=1.69]\n",
            "Epoch 11 [Val]: 100%|██████████| 14/14 [00:05<00:00,  2.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 11 | Train Loss: 1.7677 | Train Acc: 0.369 | Val Loss: 1.9934 | Val Acc: 0.252\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12 [Train]: 100%|██████████| 53/53 [00:35<00:00,  1.49it/s, loss=1.65]\n",
            "Epoch 12 [Val]: 100%|██████████| 14/14 [00:05<00:00,  2.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 12 | Train Loss: 1.7655 | Train Acc: 0.357 | Val Loss: 1.9927 | Val Acc: 0.233\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13 [Train]: 100%|██████████| 53/53 [00:35<00:00,  1.51it/s, loss=1.91]\n",
            "Epoch 13 [Val]: 100%|██████████| 14/14 [00:06<00:00,  2.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 13 | Train Loss: 1.7495 | Train Acc: 0.349 | Val Loss: 1.9770 | Val Acc: 0.252\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14 [Train]: 100%|██████████| 53/53 [00:35<00:00,  1.51it/s, loss=2.01]\n",
            "Epoch 14 [Val]: 100%|██████████| 14/14 [00:06<00:00,  2.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 14 | Train Loss: 1.7229 | Train Acc: 0.381 | Val Loss: 1.9798 | Val Acc: 0.229\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15 [Train]: 100%|██████████| 53/53 [00:34<00:00,  1.53it/s, loss=1.73]\n",
            "Epoch 15 [Val]: 100%|██████████| 14/14 [00:07<00:00,  1.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 15 | Train Loss: 1.7186 | Train Acc: 0.360 | Val Loss: 1.9684 | Val Acc: 0.243\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16 [Train]: 100%|██████████| 53/53 [00:34<00:00,  1.53it/s, loss=1.73]\n",
            "Epoch 16 [Val]: 100%|██████████| 14/14 [00:06<00:00,  2.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 16 | Train Loss: 1.6962 | Train Acc: 0.371 | Val Loss: 1.9504 | Val Acc: 0.238\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17 [Train]: 100%|██████████| 53/53 [00:34<00:00,  1.54it/s, loss=1.85]\n",
            "Epoch 17 [Val]: 100%|██████████| 14/14 [00:06<00:00,  2.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 17 | Train Loss: 1.6892 | Train Acc: 0.364 | Val Loss: 1.9015 | Val Acc: 0.295\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18 [Train]: 100%|██████████| 53/53 [00:34<00:00,  1.55it/s, loss=1.86]\n",
            "Epoch 18 [Val]: 100%|██████████| 14/14 [00:05<00:00,  2.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 18 | Train Loss: 1.6902 | Train Acc: 0.376 | Val Loss: 1.8661 | Val Acc: 0.362\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19 [Train]: 100%|██████████| 53/53 [00:35<00:00,  1.51it/s, loss=1.48]\n",
            "Epoch 19 [Val]: 100%|██████████| 14/14 [00:05<00:00,  2.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 19 | Train Loss: 1.6696 | Train Acc: 0.398 | Val Loss: 1.8273 | Val Acc: 0.371\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20 [Train]: 100%|██████████| 53/53 [00:35<00:00,  1.50it/s, loss=1.93]\n",
            "Epoch 20 [Val]: 100%|██████████| 14/14 [00:05<00:00,  2.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 20 | Train Loss: 1.6812 | Train Acc: 0.379 | Val Loss: 1.7957 | Val Acc: 0.405\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 21 [Train]: 100%|██████████| 53/53 [00:35<00:00,  1.49it/s, loss=1.65]\n",
            "Epoch 21 [Val]: 100%|██████████| 14/14 [00:05<00:00,  2.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 21 | Train Loss: 1.6751 | Train Acc: 0.396 | Val Loss: 1.7623 | Val Acc: 0.424\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 22 [Train]: 100%|██████████| 53/53 [00:35<00:00,  1.50it/s, loss=2.11]\n",
            "Epoch 22 [Val]: 100%|██████████| 14/14 [00:05<00:00,  2.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 22 | Train Loss: 1.6624 | Train Acc: 0.400 | Val Loss: 1.7586 | Val Acc: 0.390\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 23 [Train]: 100%|██████████| 53/53 [00:35<00:00,  1.50it/s, loss=1.73]\n",
            "Epoch 23 [Val]: 100%|██████████| 14/14 [00:05<00:00,  2.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 23 | Train Loss: 1.6705 | Train Acc: 0.381 | Val Loss: 1.7350 | Val Acc: 0.443\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 24 [Train]: 100%|██████████| 53/53 [00:35<00:00,  1.51it/s, loss=1.45]\n",
            "Epoch 24 [Val]: 100%|██████████| 14/14 [00:05<00:00,  2.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 24 | Train Loss: 1.6422 | Train Acc: 0.412 | Val Loss: 1.7374 | Val Acc: 0.405\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 25 [Train]: 100%|██████████| 53/53 [00:34<00:00,  1.53it/s, loss=2.33]\n",
            "Epoch 25 [Val]: 100%|██████████| 14/14 [00:06<00:00,  2.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 25 | Train Loss: 1.6745 | Train Acc: 0.375 | Val Loss: 1.7325 | Val Acc: 0.414\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 26 [Train]: 100%|██████████| 53/53 [00:34<00:00,  1.54it/s, loss=1.52]\n",
            "Epoch 26 [Val]: 100%|██████████| 14/14 [00:06<00:00,  2.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 26 | Train Loss: 1.6578 | Train Acc: 0.379 | Val Loss: 1.7342 | Val Acc: 0.405\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 27 [Train]: 100%|██████████| 53/53 [00:34<00:00,  1.54it/s, loss=1.74]\n",
            "Epoch 27 [Val]: 100%|██████████| 14/14 [00:06<00:00,  2.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 27 | Train Loss: 1.6355 | Train Acc: 0.407 | Val Loss: 1.7219 | Val Acc: 0.410\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 28 [Train]: 100%|██████████| 53/53 [00:34<00:00,  1.53it/s, loss=1.44]\n",
            "Epoch 28 [Val]: 100%|██████████| 14/14 [00:06<00:00,  2.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 28 | Train Loss: 1.6239 | Train Acc: 0.390 | Val Loss: 1.7225 | Val Acc: 0.400\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 29 [Train]: 100%|██████████| 53/53 [00:34<00:00,  1.54it/s, loss=1.46]\n",
            "Epoch 29 [Val]: 100%|██████████| 14/14 [00:05<00:00,  2.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 29 | Train Loss: 1.6408 | Train Acc: 0.411 | Val Loss: 1.7232 | Val Acc: 0.376\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 30 [Train]: 100%|██████████| 53/53 [00:35<00:00,  1.51it/s, loss=1.52]\n",
            "Epoch 30 [Val]: 100%|██████████| 14/14 [00:05<00:00,  2.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 30 | Train Loss: 1.6066 | Train Acc: 0.406 | Val Loss: 1.7217 | Val Acc: 0.400\n",
            "✅ Best model loaded.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "latest resnet 50"
      ],
      "metadata": {
        "id": "rcuAZWCLdZvZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import models, transforms\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from tqdm import tqdm\n",
        "\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "class CryDataset(Dataset):\n",
        "    def __init__(self, folder, transform=None):\n",
        "        self.paths, self.labels = [], []\n",
        "        for label in sorted(os.listdir(folder)):\n",
        "            class_dir = os.path.join(folder, label)\n",
        "            if os.path.isdir(class_dir):\n",
        "                for file in os.listdir(class_dir):\n",
        "                    if file.endswith(\".npy\"):\n",
        "                        self.paths.append(os.path.join(class_dir, file))\n",
        "                        self.labels.append(label)\n",
        "        self.classes = sorted(list(set(self.labels)))\n",
        "        self.class_to_idx = {cls: i for i, cls in enumerate(self.classes)}\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self): return len(self.paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        path = self.paths[idx]\n",
        "        label = self.class_to_idx[self.labels[idx]]\n",
        "        try:\n",
        "            mel_spec = np.load(path)\n",
        "            mel_spec = np.squeeze(mel_spec)\n",
        "            mel_norm = (mel_spec - mel_spec.min()) / (mel_spec.max() - mel_spec.min() + 1e-6)\n",
        "            img = Image.fromarray((mel_norm * 255).astype(np.uint8)).resize((224, 224)).convert(\"RGB\")\n",
        "            if self.transform: img = self.transform(img)\n",
        "            return img, label\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading {path}: {e}\")\n",
        "            return None, None\n",
        "\n",
        "def custom_collate_fn(batch):\n",
        "    batch = [b for b in batch if b[0] is not None]\n",
        "    if len(batch) == 0: return torch.empty(0), torch.empty(0)\n",
        "    imgs, labels = zip(*batch)\n",
        "    return torch.stack(imgs), torch.tensor(labels)\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomApply([transforms.ColorJitter(0.2, 0.2)], p=0.3),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5]*3, std=[0.5]*3)\n",
        "])\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5]*3, std=[0.5]*3)\n",
        "])\n",
        "\n",
        "train_data = CryDataset(\"/content/baby_cry_split/train\", transform=train_transform)\n",
        "val_data = CryDataset(\"/content/baby_cry_split/val\", transform=val_transform)\n",
        "\n",
        "batch_size = 32\n",
        "num_workers = 2\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True,\n",
        "                          collate_fn=custom_collate_fn, num_workers=num_workers, pin_memory=True)\n",
        "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False,\n",
        "                        collate_fn=custom_collate_fn, num_workers=num_workers, pin_memory=True)\n",
        "\n",
        "\n",
        "train_labels = [train_data.class_to_idx[label] for label in train_data.labels]\n",
        "class_weights = torch.tensor(\n",
        "    compute_class_weight('balanced', classes=np.unique(train_labels), y=train_labels),\n",
        "    dtype=torch.float\n",
        ").to(device)\n",
        "\n",
        "\n",
        "model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
        "model.fc = nn.Sequential(\n",
        "    nn.Dropout(0.4),\n",
        "    nn.Linear(model.fc.in_features, len(train_data.classes))\n",
        ")\n",
        "model = model.to(device)\n",
        "\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
        "optimizer = optim.Adam(model.parameters(), lr=3e-4, weight_decay=1e-4)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.5)\n",
        "\n",
        "\n",
        "best_val_loss = float(\"inf\")\n",
        "no_improve = 0\n",
        "early_stop_patience = 5\n",
        "max_epochs = 25\n",
        "\n",
        "for epoch in range(1, max_epochs + 1):\n",
        "    model.train()\n",
        "    train_loss, train_correct, train_total = 0.0, 0, 0\n",
        "    for X, y in tqdm(train_loader, desc=f\"Epoch {epoch:02d} [Train]\"):\n",
        "        if X.size(0) == 0: continue\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        out = model(X)\n",
        "        loss = criterion(out, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item() * X.size(0)\n",
        "        train_correct += (out.argmax(1) == y).sum().item()\n",
        "        train_total += X.size(0)\n",
        "    train_loss /= train_total\n",
        "    train_acc = train_correct / train_total\n",
        "\n",
        "    model.eval()\n",
        "    val_loss, val_correct, val_total = 0.0, 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in tqdm(val_loader, desc=f\"Epoch {epoch:02d} [Val]\"):\n",
        "            if X.size(0) == 0: continue\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            out = model(X)\n",
        "            loss = criterion(out, y)\n",
        "            val_loss += loss.item() * X.size(0)\n",
        "            val_correct += (out.argmax(1) == y).sum().item()\n",
        "            val_total += X.size(0)\n",
        "    val_loss /= val_total\n",
        "    val_acc = val_correct / val_total\n",
        "\n",
        "    print(f\"\\n📊 Epoch {epoch:02d} | Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.3f} | \"\n",
        "          f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.3f}\\n\")\n",
        "\n",
        "    scheduler.step(val_loss)\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        torch.save(model.state_dict(), \"best_model.pth\")\n",
        "        no_improve = 0\n",
        "    else:\n",
        "        no_improve += 1\n",
        "        if no_improve >= early_stop_patience:\n",
        "            print(\"⏹️ Early stopping triggered.\")\n",
        "            break\n",
        "\n",
        "model.load_state_dict(torch.load(\"best_model.pth\"))\n",
        "model.eval()\n",
        "print(\"✅ Best model loaded.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6DpXCZny8Qr",
        "outputId": "bdb0cd24-b8ab-49e8-c301-0508d1149927"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚀 Using device: cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 01 [Train]: 100%|██████████| 27/27 [03:26<00:00,  7.64s/it]\n",
            "Epoch 01 [Val]: 100%|██████████| 7/7 [00:17<00:00,  2.46s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 01 | Train Loss: 1.5597 | Train Acc: 0.352 | Val Loss: 1.2981 | Val Acc: 0.419\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 02 [Train]: 100%|██████████| 27/27 [03:25<00:00,  7.62s/it]\n",
            "Epoch 02 [Val]: 100%|██████████| 7/7 [00:17<00:00,  2.47s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 02 | Train Loss: 1.1991 | Train Acc: 0.442 | Val Loss: 1.3581 | Val Acc: 0.405\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 03 [Train]: 100%|██████████| 27/27 [03:30<00:00,  7.81s/it]\n",
            "Epoch 03 [Val]: 100%|██████████| 7/7 [00:18<00:00,  2.58s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 03 | Train Loss: 1.1412 | Train Acc: 0.482 | Val Loss: 1.2815 | Val Acc: 0.386\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 04 [Train]: 100%|██████████| 27/27 [03:26<00:00,  7.65s/it]\n",
            "Epoch 04 [Val]: 100%|██████████| 7/7 [00:18<00:00,  2.63s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 04 | Train Loss: 1.1367 | Train Acc: 0.471 | Val Loss: 1.2982 | Val Acc: 0.443\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 05 [Train]: 100%|██████████| 27/27 [03:25<00:00,  7.62s/it]\n",
            "Epoch 05 [Val]: 100%|██████████| 7/7 [00:18<00:00,  2.65s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 05 | Train Loss: 1.0277 | Train Acc: 0.500 | Val Loss: 1.4859 | Val Acc: 0.352\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 06 [Train]: 100%|██████████| 27/27 [03:24<00:00,  7.58s/it]\n",
            "Epoch 06 [Val]: 100%|██████████| 7/7 [00:18<00:00,  2.65s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 06 | Train Loss: 0.9690 | Train Acc: 0.523 | Val Loss: 1.2796 | Val Acc: 0.405\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 07 [Train]: 100%|██████████| 27/27 [03:25<00:00,  7.60s/it]\n",
            "Epoch 07 [Val]: 100%|██████████| 7/7 [00:18<00:00,  2.60s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 07 | Train Loss: 0.9116 | Train Acc: 0.536 | Val Loss: 1.3394 | Val Acc: 0.429\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 08 [Train]: 100%|██████████| 27/27 [03:25<00:00,  7.62s/it]\n",
            "Epoch 08 [Val]: 100%|██████████| 7/7 [00:17<00:00,  2.54s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 08 | Train Loss: 0.8672 | Train Acc: 0.536 | Val Loss: 1.3724 | Val Acc: 0.400\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 09 [Train]: 100%|██████████| 27/27 [03:25<00:00,  7.62s/it]\n",
            "Epoch 09 [Val]: 100%|██████████| 7/7 [00:17<00:00,  2.49s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 09 | Train Loss: 0.7299 | Train Acc: 0.610 | Val Loss: 1.4851 | Val Acc: 0.400\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10 [Train]: 100%|██████████| 27/27 [03:26<00:00,  7.65s/it]\n",
            "Epoch 10 [Val]: 100%|██████████| 7/7 [00:17<00:00,  2.48s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 10 | Train Loss: 0.6986 | Train Acc: 0.625 | Val Loss: 1.7032 | Val Acc: 0.376\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11 [Train]: 100%|██████████| 27/27 [03:26<00:00,  7.63s/it]\n",
            "Epoch 11 [Val]: 100%|██████████| 7/7 [00:17<00:00,  2.48s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Epoch 11 | Train Loss: 0.6216 | Train Acc: 0.637 | Val Loss: 1.4286 | Val Acc: 0.438\n",
            "\n",
            "⏹️ Early stopping triggered.\n",
            "✅ Best model loaded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "resnet 18"
      ],
      "metadata": {
        "id": "98lFvL-X5nv1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import models\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "\n",
        "class CryDataset(Dataset):\n",
        "    def __init__(self, folder, transform=None):\n",
        "        self.paths, self.labels = [], []\n",
        "\n",
        "        for label in sorted(os.listdir(folder)):\n",
        "            class_dir = os.path.join(folder, label)\n",
        "            if os.path.isdir(class_dir):\n",
        "                for file in os.listdir(class_dir):\n",
        "                    if file.endswith(\".npy\"):\n",
        "                        self.paths.append(os.path.join(class_dir, file))\n",
        "                        self.labels.append(label)\n",
        "\n",
        "        self.classes = sorted(set(self.labels))\n",
        "        self.class_to_idx = {cls: i for i, cls in enumerate(self.classes)}\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        try:\n",
        "            path = self.paths[idx]\n",
        "            label = self.class_to_idx[self.labels[idx]]\n",
        "            mel = np.squeeze(np.load(path))\n",
        "\n",
        "            if mel.ndim != 2:\n",
        "                raise ValueError(\"Invalid mel shape\")\n",
        "\n",
        "            mel_norm = (mel - mel.min()) / (mel.max() - mel.min() + 1e-6)\n",
        "            img = Image.fromarray((mel_norm * 255).astype(np.uint8)).resize((224, 224)).convert(\"RGB\")\n",
        "            if self.transform:\n",
        "                img = self.transform(img)\n",
        "            return img, label\n",
        "\n",
        "        except:\n",
        "            return None, None\n",
        "\n",
        "\n",
        "def custom_collate_fn(batch):\n",
        "    batch = [b for b in batch if b[0] is not None]\n",
        "    if not batch:\n",
        "        return torch.empty(0), torch.empty(0)\n",
        "    imgs, labels = zip(*batch)\n",
        "    return torch.stack(imgs), torch.tensor(labels)\n",
        "\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ColorJitter(0.2, 0.2, 0.2, 0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5]*3, [0.5]*3),\n",
        "    transforms.RandomErasing(p=0.25)\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
        "])\n",
        "\n",
        "\n",
        "train_data = CryDataset(\"/content/baby_cry_split/train\", transform=train_transform)\n",
        "val_data   = CryDataset(\"/content/baby_cry_split/val\", transform=val_transform)\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=16, shuffle=True, collate_fn=custom_collate_fn)\n",
        "val_loader   = DataLoader(val_data, batch_size=16, shuffle=False, collate_fn=custom_collate_fn)\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "base_model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
        "for param in base_model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "in_features = base_model.fc.in_features\n",
        "base_model.fc = torch.nn.Sequential(\n",
        "    torch.nn.Dropout(0.5),\n",
        "    torch.nn.Linear(in_features, len(train_data.classes))\n",
        ")\n",
        "model = base_model.to(device)\n",
        "\n",
        "\n",
        "y_train_encoded = [train_data.class_to_idx[label] for label in train_data.labels]\n",
        "class_weights = compute_class_weight('balanced', classes=np.unique(y_train_encoded), y=y_train_encoded)\n",
        "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
        "optimizer = torch.optim.Adam(model.fc.parameters(), lr=3e-5, weight_decay=1e-4)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=2, factor=0.5)\n",
        "\n",
        "\n",
        "best_val_loss = float(\"inf\")\n",
        "early_stop_patience = 7\n",
        "no_improve = 0\n",
        "\n",
        "for epoch in range(1, 31):\n",
        "    model.train()\n",
        "    train_loss, correct, total = 0.0, 0, 0\n",
        "\n",
        "    for X, y in train_loader:\n",
        "        if X.size(0) == 0: continue\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(X)\n",
        "        loss = criterion(outputs, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item() * X.size(0)\n",
        "        correct += (outputs.argmax(1) == y).sum().item()\n",
        "        total += X.size(0)\n",
        "\n",
        "    train_loss /= total\n",
        "    train_acc = correct / total\n",
        "\n",
        "    model.eval()\n",
        "    val_loss, val_correct, val_total = 0.0, 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in val_loader:\n",
        "            if X.size(0) == 0: continue\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            outputs = model(X)\n",
        "            loss = criterion(outputs, y)\n",
        "\n",
        "            val_loss += loss.item() * X.size(0)\n",
        "            val_correct += (outputs.argmax(1) == y).sum().item()\n",
        "            val_total += X.size(0)\n",
        "\n",
        "    val_loss /= val_total\n",
        "    val_acc = val_correct / val_total\n",
        "\n",
        "    print(f\"Epoch {epoch:02d} | Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.3f} | Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.3f}\")\n",
        "    scheduler.step(val_loss)\n",
        "\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        torch.save(model.state_dict(), \"best_model.pth\")\n",
        "        no_improve = 0\n",
        "    else:\n",
        "        no_improve += 1\n",
        "        if no_improve >= early_stop_patience:\n",
        "            print(\"⏹️ Early stopping triggered.\")\n",
        "            break\n",
        "\n",
        "model.load_state_dict(torch.load(\"best_model.pth\"))\n",
        "model.eval()\n",
        "print(\"✅ Best model loaded.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2wdA8gDVcCS",
        "outputId": "37909489-7504-491a-dda3-9c4eb50bba38"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:01<00:00, 37.9MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 01 | Train Loss: 2.5808 | Train Acc: 0.106 | Val Loss: 2.3318 | Val Acc: 0.062\n",
            "Epoch 02 | Train Loss: 2.4340 | Train Acc: 0.089 | Val Loss: 2.2956 | Val Acc: 0.081\n",
            "Epoch 03 | Train Loss: 2.4018 | Train Acc: 0.100 | Val Loss: 2.2507 | Val Acc: 0.110\n",
            "Epoch 04 | Train Loss: 2.3876 | Train Acc: 0.113 | Val Loss: 2.2438 | Val Acc: 0.114\n",
            "Epoch 05 | Train Loss: 2.3891 | Train Acc: 0.120 | Val Loss: 2.2269 | Val Acc: 0.105\n",
            "Epoch 06 | Train Loss: 2.3536 | Train Acc: 0.117 | Val Loss: 2.2132 | Val Acc: 0.133\n",
            "Epoch 07 | Train Loss: 2.3443 | Train Acc: 0.130 | Val Loss: 2.1890 | Val Acc: 0.148\n",
            "Epoch 08 | Train Loss: 2.2792 | Train Acc: 0.143 | Val Loss: 2.1716 | Val Acc: 0.176\n",
            "Epoch 09 | Train Loss: 2.2843 | Train Acc: 0.131 | Val Loss: 2.1488 | Val Acc: 0.171\n",
            "Epoch 10 | Train Loss: 2.2515 | Train Acc: 0.151 | Val Loss: 2.1341 | Val Acc: 0.195\n",
            "Epoch 11 | Train Loss: 2.2792 | Train Acc: 0.123 | Val Loss: 2.1246 | Val Acc: 0.205\n",
            "Epoch 12 | Train Loss: 2.2803 | Train Acc: 0.157 | Val Loss: 2.1112 | Val Acc: 0.186\n",
            "Epoch 13 | Train Loss: 2.2491 | Train Acc: 0.143 | Val Loss: 2.0959 | Val Acc: 0.219\n",
            "Epoch 14 | Train Loss: 2.2039 | Train Acc: 0.188 | Val Loss: 2.0814 | Val Acc: 0.224\n",
            "Epoch 15 | Train Loss: 2.1780 | Train Acc: 0.173 | Val Loss: 2.0750 | Val Acc: 0.219\n",
            "Epoch 16 | Train Loss: 2.2099 | Train Acc: 0.163 | Val Loss: 2.0633 | Val Acc: 0.219\n",
            "Epoch 17 | Train Loss: 2.1850 | Train Acc: 0.169 | Val Loss: 2.0593 | Val Acc: 0.252\n",
            "Epoch 18 | Train Loss: 2.2090 | Train Acc: 0.175 | Val Loss: 2.0454 | Val Acc: 0.267\n",
            "Epoch 19 | Train Loss: 2.1687 | Train Acc: 0.173 | Val Loss: 2.0381 | Val Acc: 0.262\n",
            "Epoch 20 | Train Loss: 2.1728 | Train Acc: 0.176 | Val Loss: 2.0297 | Val Acc: 0.257\n",
            "Epoch 21 | Train Loss: 2.1694 | Train Acc: 0.176 | Val Loss: 2.0152 | Val Acc: 0.295\n",
            "Epoch 22 | Train Loss: 2.1424 | Train Acc: 0.171 | Val Loss: 2.0056 | Val Acc: 0.281\n",
            "Epoch 23 | Train Loss: 2.1321 | Train Acc: 0.194 | Val Loss: 1.9972 | Val Acc: 0.281\n",
            "Epoch 24 | Train Loss: 2.1234 | Train Acc: 0.199 | Val Loss: 1.9900 | Val Acc: 0.290\n",
            "Epoch 25 | Train Loss: 2.1457 | Train Acc: 0.206 | Val Loss: 1.9733 | Val Acc: 0.290\n",
            "Epoch 26 | Train Loss: 2.1037 | Train Acc: 0.201 | Val Loss: 1.9691 | Val Acc: 0.286\n",
            "Epoch 27 | Train Loss: 2.0933 | Train Acc: 0.199 | Val Loss: 1.9630 | Val Acc: 0.276\n",
            "Epoch 28 | Train Loss: 2.0667 | Train Acc: 0.213 | Val Loss: 1.9552 | Val Acc: 0.310\n",
            "Epoch 29 | Train Loss: 2.0514 | Train Acc: 0.205 | Val Loss: 1.9492 | Val Acc: 0.295\n",
            "Epoch 30 | Train Loss: 2.0516 | Train Acc: 0.212 | Val Loss: 1.9387 | Val Acc: 0.295\n",
            "✅ Best model loaded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Yamnet"
      ],
      "metadata": {
        "id": "-Njqfwy3Kcwu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "import zipfile\n",
        "from tensorflow.keras import layers, regularizers\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import keras_tuner as kt\n",
        "from tensorflow.keras import layers, regularizers\n",
        "from keras_tuner.tuners import BayesianOptimization\n",
        "!pip install keras_tuner\n",
        "\n",
        "# Assuming the zip is uploaded to your Drive\n",
        "zip_path = '/content/drive/MyDrive/Baby_Crying_Sounds.zip'\n",
        "extract_path = '/content/drive/MyDrive/baby_cry_data'\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "# Load YAMNet model\n",
        "yamnet_model = hub.load('https://tfhub.dev/google/yamnet/1')\n",
        "\n",
        "# Base path: folders like /content/baby_cry_data/BabyCryingSounds/hungry/*.wav\n",
        "base_dir = \"/content/drive/MyDrive/baby_cry_data/Baby Crying Sounds\"\n",
        "\n",
        "# Output base path to save embeddings\n",
        "output_base = \"/content/drive/MyDrive/baby_cry_embeddings\"\n",
        "\n",
        "# Step 1: Helper to load waveform at 16 kHz\n",
        "def load_audio_16k(file_path):\n",
        "    waveform, sr = librosa.load(file_path, sr=16000, mono=True)\n",
        "    return waveform\n",
        "\n",
        "\n",
        "def augment_audio(waveform, sr=16000):\n",
        "    choice = random.choice(['pitch', 'stretch', 'none'])\n",
        "\n",
        "    if choice == 'pitch':\n",
        "        n_steps = random.choice([-2, -1, 1, 2])\n",
        "        return librosa.effects.pitch_shift(waveform, sr=sr, n_steps=n_steps)\n",
        "\n",
        "    elif choice == 'stretch':\n",
        "        rate = random.uniform(0.8, 1.2)\n",
        "        return librosa.effects.time_stretch(waveform, rate=rate)\n",
        "\n",
        "    else:\n",
        "        return waveform\n",
        "\n",
        "\n",
        "\n",
        "def extract_yamnet_embedding(file_path, augment=True):\n",
        "    waveform = load_audio_16k(file_path)\n",
        "\n",
        "    if augment:\n",
        "        waveform = augment_audio(waveform, sr=16000)\n",
        "\n",
        "    waveform = tf.convert_to_tensor(waveform, dtype=tf.float32)\n",
        "    scores, embeddings, spectrogram = yamnet_model(waveform)\n",
        "    return tf.reduce_mean(embeddings, axis=0).numpy()\n",
        "\n",
        "\n",
        "\n",
        "# Step 3: Loop through folders and collect data\n",
        "X = []\n",
        "y = []\n",
        "file_paths = []\n",
        "\n",
        "labels = sorted([label for label in os.listdir(base_dir) if os.path.isdir(os.path.join(base_dir, label))])\n",
        "\n",
        "for label in labels:\n",
        "    folder = os.path.join(base_dir, label)\n",
        "    for fname in tqdm(os.listdir(folder), desc=f\"Processing {label}\"):\n",
        "        if not fname.lower().endswith(('.wav', '.mp3', '.ogg')):\n",
        "            continue\n",
        "        fpath = os.path.join(folder, fname)\n",
        "        try:\n",
        "            # Original sample\n",
        "            emb = extract_yamnet_embedding(fpath, augment=False)\n",
        "            X.append(emb)\n",
        "            y.append(label)\n",
        "            file_paths.append(fpath)\n",
        "\n",
        "            # Augmented copies (e.g., 2 extra variants)\n",
        "            for _ in range(2):\n",
        "                emb_aug = extract_yamnet_embedding(fpath, augment=True)\n",
        "                X.append(emb_aug)\n",
        "                y.append(label)\n",
        "                file_paths.append(fpath)  # or just fpath again\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Error processing {fpath}: {e}\")\n",
        "\n",
        "\n",
        "# Step 4: Encode labels\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)\n",
        "label_names = le.classes_\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "# Count occurrences of each class in the combined dataset\n",
        "# y_encoded contains the integer encoded labels for all files\n",
        "class_counts = Counter(y_encoded)\n",
        "\n",
        "# Map integer indices back to class names\n",
        "label_counts = {class_names[i]: count for i, count in class_counts.items()}\n",
        "\n",
        "print(\"Number of audio files per category:\")\n",
        "for label, count in label_counts.items():\n",
        "    print(f\"{label}: {count}\")\n",
        "\n",
        "\n",
        "# Step 5: Split into train, val, test\n",
        "X_train_val, X_test, y_train_val, y_test, f_train_val, f_test = train_test_split(\n",
        "    X, y_encoded, file_paths, test_size=0.1, random_state=42, stratify=y_encoded)\n",
        "\n",
        "X_train, X_val, y_train, y_val, f_train, f_val = train_test_split(\n",
        "    X_train_val, y_train_val, f_train_val, test_size=0.1, random_state=42, stratify=y_train_val)\n",
        "\n",
        "\n",
        "splits = {\n",
        "    'train': (X_train, y_train),\n",
        "    'val': (X_val, y_val),\n",
        "    'test': (X_test, y_test)\n",
        "}\n",
        "\n",
        "# Step 6: Save to folders by split/class\n",
        "for split in ['train', 'val', 'test']:\n",
        "    for class_name in label_names:\n",
        "        os.makedirs(os.path.join(output_base, split, class_name), exist_ok=True)\n",
        "\n",
        "def save_embeddings(X_split, y_split, split_name):\n",
        "    for i, (emb, label_idx) in enumerate(zip(X_split, y_split)):\n",
        "        class_name = label_names[label_idx]\n",
        "        save_path = os.path.join(output_base, split_name, class_name, f\"yamnet_{i}.npy\")\n",
        "        np.save(save_path, emb)\n",
        "\n",
        "# Save all splits\n",
        "save_embeddings(X_train, y_train, \"train\")\n",
        "save_embeddings(X_val, y_val, \"val\")\n",
        "save_embeddings(X_test, y_test, \"test\")\n",
        "\n",
        "print(\"✅ Done: Embeddings extracted, split, and saved by class.\")\n",
        "\n",
        "def load_embeddings(data_dir):\n",
        "    X, y = [], []\n",
        "    class_names = sorted(os.listdir(data_dir))  # ['belly pain', 'burping', ...]\n",
        "    label_to_idx = {name: idx for idx, name in enumerate(class_names)}\n",
        "\n",
        "    for label in class_names:\n",
        "        label_dir = os.path.join(data_dir, label)\n",
        "        for fname in os.listdir(label_dir):\n",
        "            if fname.endswith('.npy'):\n",
        "                path = os.path.join(label_dir, fname)\n",
        "                emb = np.load(path)\n",
        "                X.append(emb)\n",
        "                y.append(label_to_idx[label])\n",
        "    return np.array(X), np.array(y), class_names\n",
        "\n",
        "\n",
        "train_dir = '/content/drive/MyDrive/baby_cry_embeddings/train'\n",
        "val_dir   = '/content/drive/MyDrive/baby_cry_embeddings/val'\n",
        "test_dir  = '/content/drive/MyDrive/baby_cry_embeddings/test'\n",
        "\n",
        "X_train, y_train, class_names = load_embeddings(train_dir)\n",
        "X_val, y_val, _ = load_embeddings(val_dir)\n",
        "X_test, y_test, _ = load_embeddings(test_dir)\n",
        "\n",
        "print(f\"✅ Loaded: {X_train.shape[0]} train | {X_val.shape[0]} val | {X_test.shape[0]} test\")\n",
        "\n",
        "\n",
        "#Build the model with best hyperparameters\n",
        "model = tf.keras.Sequential([\n",
        "    layers.Input(shape=(1024,)),\n",
        "\n",
        "    # Layer 1\n",
        "    layers.Dense(526, use_bias=False,\n",
        "                 kernel_regularizer=regularizers.l2(0.0001897)),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Activation('relu'),\n",
        "    layers.Dropout(0.4),\n",
        "\n",
        "    # Layer 2\n",
        "    layers.Dense(256, use_bias=False,\n",
        "                 kernel_regularizer=regularizers.l2(0.0002384)),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Activation('relu'),\n",
        "    layers.Dropout(0.4),\n",
        "\n",
        "\n",
        "    layers.Dense(128, use_bias=False,\n",
        "    kernel_regularizer=regularizers.l2(0.0002384)),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Activation('relu'),\n",
        "\n",
        "    # Output layer\n",
        "    layers.Dense(len(np.unique(y_train)), activation=\"softmax\")\n",
        "])\n",
        "\n",
        "# Compile\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001342)\n",
        "\n",
        "model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "early_stop = tf.keras.callbacks.EarlyStopping(\n",
        "    patience=15, restore_best_weights=True\n",
        ")\n",
        "\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "    factor=0.5, patience=7, verbose=1, min_lr=1e-6\n",
        ")\n",
        "\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
        "    \"best_yamnet_model.h5\", save_best_only=True, verbose=1\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=100,\n",
        "    batch_size=32,\n",
        "    callbacks=[early_stop, reduce_lr, checkpoint],\n",
        "    # class_weight=class_weight_dict\n",
        ")\n",
        "\n",
        "# Get predictions as class indices\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "print(f\"\\n✅ Final Test Accuracy: {test_acc:.2%}\")\n",
        "\n",
        "y_pred = model.predict(X_test).argmax(axis=1)\n",
        "\n",
        "print(classification_report(y_test, y_pred, target_names=class_names))\n",
        "\n",
        "def build_model(hp):\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Input(shape=(1024,)))\n",
        "\n",
        "    for i in range(hp.Int(\"num_layers\", 1, 3)):\n",
        "        units = hp.Int(f\"units_{i}\", min_value=64, max_value=512, step=64)\n",
        "        l2 = hp.Float(f\"l2_{i}\", 1e-4, 1e-2, sampling=\"log\")\n",
        "\n",
        "        model.add(layers.Dense(units, use_bias=False,\n",
        "                               kernel_regularizer=regularizers.l2(l2)))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.Activation('relu'))\n",
        "\n",
        "        dropout = hp.Float(f\"dropout_{i}\", 0.3, 0.6, step=0.1)\n",
        "        model.add(layers.Dropout(dropout))\n",
        "\n",
        "    model.add(layers.Dense(len(np.unique(y_train)), activation=\"softmax\"))\n",
        "\n",
        "    lr = hp.Float(\"lr\", 1e-4, 1e-2, sampling=\"log\")\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss=\"sparse_categorical_crossentropy\",\n",
        "        metrics=[\"accuracy\"]\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "tuner = BayesianOptimization(\n",
        "    build_model,\n",
        "    objective=\"val_accuracy\",\n",
        "    max_trials=20,\n",
        "    directory=\"yamnet_tuning\",\n",
        "    project_name=\"bayesian_final\"\n",
        ")\n",
        "\n",
        "early_stop = tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(\"best_model.h5\", save_best_only=True)\n",
        "tuner.search(X_train, y_train, epochs=30, validation_data=(X_val, y_val), callbacks=[early_stop, checkpoint])\n",
        "\n",
        "\n",
        "best_model = tuner.get_best_models(num_models=1)[0]\n",
        "best_hp = tuner.get_best_hyperparameters(1)[0]\n",
        "\n",
        "print(\"Best hyperparameters:\")\n",
        "print(best_hp.values)\n",
        "\n",
        "loss, acc = best_model.evaluate(X_test, y_test)\n",
        "print(f\"Test Accuracy: {acc:.2f}\")\n",
        "\n",
        "from IPython.display import Audio\n",
        "\n",
        "true_labels = [class_names[i] for i in y_test]\n",
        "pred_labels = [class_names[i] for i in y_pred]\n",
        "\n",
        "for i in range(10):  # show first 10\n",
        "    print(f\"File: {f_test[i]}\")\n",
        "    print(f\"True label: {true_labels[i]}\")\n",
        "    print(f\"Predicted:  {pred_labels[i]}\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "i = 212  # index of interest\n",
        "print(f\"True: {true_labels[i]}, Predicted: {pred_labels[i]}\")\n",
        "Audio(filename=f_test[i])  #Use filename for file paths"
      ],
      "metadata": {
        "id": "0IWPak04KaB4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}